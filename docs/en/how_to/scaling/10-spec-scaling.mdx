---
weight: 10
sourceSHA: dd4cdcf8f8aff1430fa04fc27e97bf8b6f27fc4bcf0cfc3e6f1bdc5d4d946b4c
---

# Instance Specification Change

Resource allocation adjustments are essential for maintaining optimal Redis performance as your data volumes grow. Proactively scaling your Redis instances before reaching storage or performance thresholds ensures continuous service availability and prevents degraded performance.

## Operational Constraints

1. **Scheduling Configuration Compatibility**: When scaling replica counts, ensure the requested number complies with any existing node scheduling constraints (labels, taints, tolerations) configured for the instance.

2. **Sentinel Mode Storage Consistency**: In Sentinel deployments, all nodes (primary and replicas) must maintain identical storage capacity allocations to ensure proper replication and failover capabilities.

3. **Cluster Mode Scaling Flexibility**: In Cluster deployments, individual shards can be scaled independently, but within each shard, all replica nodes must maintain storage capacity parity with their primary node.

4. **Resource Allocation Considerations**: When modifying CPU and memory allocations:
   - Analyze historical usage patterns and projected growth
   - Verify cluster resource availability before scaling
   - Consider Redis memory overhead requirements (~30% above dataset size)
   - Implement gradual scaling for production environments

   Inadequate resource allocation may cause instance instability, while excessive allocation leads to inefficient resource utilization.

## Implementation Steps

<Tabs>
  <Tab label="CLI">
    Instance specifications are controlled through the `spec.resources` field in the Redis custom resource (see [API documentation](../../apis/kubernetes_apis/redis/redis) for comprehensive parameter details).
    
    ```bash
    # Update instance resources to 300m CPU and 300Mi memory
    $ kubectl -n default patch redis s6 --type=merge --patch='{"spec": {"resources":{"limits":{"cpu": "300m","memory":"300Mi"},"requests":{"cpu":"300m", "memory":"300Mi"}}}}'
    ```
    
    To monitor the scaling operation progress:
    
    ```bash
    $ kubectl -n default get redis s6 -w
    ```
  </Tab>
  
  <Tab label="Web Console">
    1. Navigate to **Redis** in the left navigation bar.
    
    2. Select the ***namespace name*** containing your instance.
    
    3. Click on the ***instance name*** to access its details.
    
    4. In the **Details** tab, locate the topology diagram and click **Update Specifications** in the toolbar.
    
    5. Configure the scaling parameters:
       - Adjust replica count if needed (subject to architectural constraints)
       - Specify new CPU and memory allocations
       - Modify storage capacity if required
    
    6. Click **Update** to initiate the scaling operation.
  </Tab>
</Tabs>

The system will apply the configuration changes progressively to minimize service disruption. The topology view will reflect the updated specifications once the scaling operation completes successfully.

> **Performance Tip**: For instances with large datasets, consider performing scaling operations during periods of lower traffic to minimize potential impact on client operations.
